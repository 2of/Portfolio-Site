[


    {
        "name": "geolocate1",
        "title": "Machine Learning for Neighbourhood-Scale GeoLocalization of Street Level Imagery from Local Image Features",
        "subtitle": "Leveraging object detection, text embeddings, and colour profiling for geographic coordinate prediction.",
       
       
        "heroLinks": [
          {
            "title" : "Medium",
            "type" : "Article",
            "to" :  "/404"
          },{
            "title" : "Github",
            "type" : "Code",
            "to" :  "/404"
          },{
            "title" : "Thesis",
            "type" : "Academic",
            "to" :  "/404"
          }
          ,{
            "title" : "Video",
            "type" : "Video",
            "to" :  "/404"
          }
        ],
        "sections": [
          {
            "name": "What's Involved",
            "type": "text",
            "boost": true,
            "items": [
              {
                "type": "paragraph",
                "text": ""
              },{
                "type": "image",
                "src": "assets/images/home_vintage.gif",
                "alt": "Street level imagery"
              },
              {
                "type": "pills",
                "pills": ["Machine Learning", "AI", "Deep Learning", "Multi-Scale Prediction", "Fine Tuning / Transfer Learning","Large Data Processing", "Neural Network Design", "Neural Network Performance Analysis", "Scalable Neural Network Design", "Python3", "Tensorflow", "Keras", ".... etc" ]
              }, 
              {
                "type": "paragraph",
                "text": "This Project designs and implements a method for Neighbourhood scale Geolocalization for Street Level Imagery using Machine Learning and Deep Learning Methods and explores in great depth the performance and learning of these methods"
              },{
                "type":"link",
                "to" :"/404",
                "label" :"GitHub Repository"
              },{
                "type":"link",
                "to" :"/404",
                "label" :"Thesis"
              }              
            ]
          },
          {
            "name": "Methodology",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "The proposed method heavily uses transfer learning for both object detection and text processing. A fine-tuned YOLOv11 model is used to detect GeoInformers, such as signage, crosswalks, and traffic lights, which serve as crucial geo-informative features."
              },
              {
                "type": "highlight",
                "text": "Transfer learning is applied to adapt the YOLOv11 model to detect new classes of objects, providing high efficiency with smaller datasets."
              },
              {
                "type": "paragraph",
                "text": "Additionally, text extracted from street signage is processed using the SBERT all-MiniLM-L6-v2 model to convert the raw OCR output into dense embeddings, capturing the semantic meaning of the words and their geographical context."
              },
              {
                "type": "highlight",
                "text": "Key advantage: The SBERT model is chosen for its ability to capture contextual relationships between geographical terms and provide compact embeddings that integrate well with other features."
              },
              {
                "type": "image",
                "src": "/assets/images/model_diagram.png",
                "alt": "Diagram showing the integration of YOLO, SBERT, and colour histograms into the geolocalisation model."
              }
            ]
          },
          {
            "name": "Challenges Encountered",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Throughout the research, several challenges were encountered. One of the main difficulties was overfitting, where the full-image model learned to predict locations in densely sampled areas rather than generalizable features."
              },
              {
                "type": "highlight",
                "text": "Overfitting became evident when predictions were biased toward densely populated regions, undermining the model's ability to generalize to more sparsely represented areas."
              },
              {
                "type": "paragraph",
                "text": "Another challenge was the insufficient separability of concatenated object and text embeddings, which hindered effective clustering and geo-location grouping."
              },
              {
                "type": "highlight",
                "text": "A lack of clear distinctions between detected objects and extracted text in the embeddings led to difficulties when attempting to use K-means clustering."
              },
              {
                "type": "pills",
                "pills": ["Overfitting", "Clustering Issues", "Data Imbalances", "Attention Mechanisms"]
              }
            ]
          },
          {
            "name": "Data and Datasets",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "The model was trained using two primary datasets: the Overall Image Embeddings Dataset (151,510 records) and the Signage Dataset (381,234 records), both derived from Mapillary API and Google Street View."
              },
              {
                "type": "highlight",
                "text": "Key insight: The data from Mapillary was essential in providing a variety of street-level images, but data density imbalances presented challenges in learning generalizable features."
              },
              {
                "type": "image",
                "src": "/assets/images/dataset_distribution.png",
                "alt": "Distribution of data across different areas within the Chicago region."
              },
              {
                "type": "paragraph",
                "text": "Images were processed to extract object detections, text embeddings, and colour histograms, which were then used as input for the machine learning models."
              }
            ]
          },
          {
            "name": "Transfer Learning and Pretrained Models",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Transfer learning played a key role in this research. The pre-trained YOLOv11 model with a ResNet100 backbone provided a strong base for detecting geo-informative objects."
              },
              {
                "type": "highlight",
                "text": "Transfer learning enabled the YOLOv11 model to be adapted to detect specific objects like signage, which would have been difficult with small custom datasets."
              },
              {
                "type": "paragraph",
                "text": "For text processing, SBERT was used to generate semantic embeddings of the extracted text, allowing for better handling of geographical terms and improving the overall geolocalisation process."
              },
              {
                "type": "highlight",
                "text": "The use of pretrained embeddings for both text and objects reduced the need for extensive retraining, allowing the model to focus on the more complex aspects of geolocalisation."
              }
            ]
          },
          {
            "name": "Attention Mechanisms and Results",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Attention mechanisms were integrated into the CNN and Multi-Dense Network models to help focus on the most geo-informative parts of the input features."
              },
              {
                "type": "highlight",
                "text": "However, the attention mechanisms did not always yield positive results, as they sometimes introduced noise and exacerbated the overfitting problem, particularly in dense areas."
              },
              {
                "type": "paragraph",
                "text": "Despite the challenges with attention, the models showed promise in reducing mean squared error (MSE), though predictions remained concentrated in high-density regions."
              },
              {
                "type": "image",
                "src": "/assets/images/attention_results.png",
                "alt": "Results showing the impact of attention mechanisms on geolocalisation performance."
              }
            ]
          },
          {
            "name": "Future Work",
            "type": "text",
            "items": [
              {
                "type": "paragraph",
                "text": "Several avenues for improvement have been identified, such as addressing data density issues through subsampling or incorporating multiple datasets to improve model generalization."
              },
              {
                "type": "highlight",
                "text": "Future work will focus on exploring alternative geolocalisation approaches, like GeoCells, and refining clustering techniques to better handle the geo-informative features from text, objects, and colour histograms."
              },
              {
                "type": "paragraph",
                "text": "Additionally, the model could benefit from sequences of images, similar to LSTM networks, to capture spatial relationships and reduce the impact of variations in viewpoint."
              },
              {
                "type": "pills",
                "pills": ["Data Augmentation", "GeoCells", "Clustering", "LSTM Networks"]
              }
            ]
          }
        ],
        "link": {
          "text": "Read More About This Geolocalisation Method",
          "url": "https://example.com/geolocalisation-method"
        }
      },
      
    
      {
        "name": "site1",
        "title": "This Website! / Responsive REACT Front End",
        "subtitle": "Look, it's just hosted on GitHub Pages",
       
        "sections": [
            {
                "name": "Introduction",
                "type": "text",
                "boost": true,
                "items": [
                    {
                        "type": "paragraph",
                        "text": "This is the website you're on right now! It's built entirely with React and serves as a playground for experimenting with front-end development. The goal was to keep things simple and fun while exploring React's capabilities."
                    },
                    {
                        "type": "pills",
                        "pills": ["React", "SCSS", "React-Router-Dom"]
                    },
                    {
                        "type": "paragraph",
                        "text": "I intentionally avoided using too many libraries. Instead, I relied on SCSS for styling and React Router for navigation, alongside React's built-in hooks. This approach kept the project lightweight and allowed me to focus on learning and creativity."
                    },
                    {
                        "type": "highlight",
                        "text": "The entire site is powered by React and SCSS, with minimal dependencies. It's a testament to how much you can do with just the basics."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/default_other.jpeg",
                        "alt": "Website homepage screenshot"
                    },
                    {
                        "type": "pills",
                        "pills": ["Vue", "Firebase"]
                    }
                ]
            },
            {
                "name": "Things it Does",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "One of the coolest features is the ability to click on images and 'portal' them to earlier in the DOM. This creates a dynamic, interactive experience that feels seamless and modern."
                    },
                    {
                        "type": "highlight",
                        "text": "Global contexts are used extensively throughout the site. For example, the navigation bar can jump and blur based on user interactions, and buttons can be added to the navigation bar from further up the React render stack. Props are passed around to manage state and functionality elegantly."
                    },
                    {
                        "type": "paragraph",
                        "text": "The site is built with React and SCSS, and while there's a lot of CSS, it's intentionally not overly reused. The idea was to have fun and experiment with styles, though there are global styles and a standard set of utilities in the app.scss file for consistency."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/website_architecture.png",
                        "alt": "Website architecture diagram"
                    },
                    {
                        "type": "paragraph",
                        "text": "Oh, and that tooltip you see? It's powered by a global context too. I thought it was a fun little addition to enhance the user experience."
                    }
                ]
            },
            {
                "name": "Behind the Scenes",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "The entire article format you're reading is defined in a custom JSON markup language. Here's how it works: I write out the content in MS Word, use ChatGPT to convert it into the schema, and then fine-tune it manually. The schema itself lives in the /assets folder, and while it's currently blank, I plan to add support for raw JSON in the column renderer when I get the chance."
                    },
                    {
                        "type": "highlight",
                        "text": "The format supports a variety of elements, including links, qualification sections, pills (like the ones above!), highlights, inline images, and special 'boost sections' to emphasize key points."
                    },
                    {
                        "type": "paragraph",
                        "text": "This approach makes it easy to structure content dynamically and keep the site flexible for future updates. It's a bit unconventional, but it works perfectly for my needs."
                    }
                ]
            }
        ],
        "link": {
            "text": "Explore the Code",
            "url": "/project-two"
        },
        "image": "project2.jpg"
    },
    {
        "name": "chrome1",
        "title": "NZ's (very very briefly) most downloaded Chrome Extension",
        "subtitle": "It did make the reddit FrontPage...",
        "sections": [
            {
                "name": "Introduction",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "This Chrome Extension briefly became New Zealand's most downloaded extension after gaining traction on Reddit's front page. The extension was designed to simplify a common task for users, leading to its viral popularity."
                    },
                    {
                        "type": "highlight",
                        "text": "Key achievement: Gained viral popularity and thousands of downloads in a single day."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/extension_screenshot.png",
                        "alt": "Extension in action"
                    },
                    {
                        "type": "pills",
                        "pills": ["JS", "Manifest V3"]
                    }
                ]
            },
            {
                "name": "Development and Features",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "The extension was built using JavaScript and Chrome's Manifest V3. It featured a simple, intuitive interface and was designed to be lightweight and fast."
                    },
                    {
                        "type": "paragraph",
                        "text": "The extension's popup interface was designed for ease of use, with clear instructions and minimal clutter. It gained traction after being shared on Reddit, leading to a surge in downloads."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/reddit_post.png",
                        "alt": "Reddit post screenshot"
                    }
                ]
            }
        ],
        "link": {
            "text": "Learn More About the Extension",
            "url": "/project-three"
        },
        "image": "project3.jpg"
    },
    {
        "name": "chess1",
        "title": "Bad Chess AI Compilation",
        "subtitle": "Not bad bots, Architecturally moronic approaches to Chess.. for fun!",
        "sections": [
            {
                "name": "Introduction",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "This project is a compilation of intentionally poorly designed chess AIs, created for fun and experimentation. The goal was to explore unconventional and humorous approaches to chess AI architecture."
                    },
                    {
                        "type": "highlight",
                        "text": "Key feature: Explored unconventional and humorous approaches to chess AI architecture."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/chessboard.png",
                        "alt": "Chessboard with AI move"
                    },
                    {
                        "type": "pills",
                        "pills": ["CNNs", "Expo"]
                    }
                ]
            },
            {
                "name": "AI Designs",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "The project included several AIs with intentionally flawed designs, such as an AI that always prioritizes moving its pawns or one that randomly sacrifices its queen. These designs were implemented using convolutional neural networks (CNNs) and other machine learning techniques."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/chess_ai_diagram.png",
                        "alt": "Chess AI architecture diagram"
                    }
                ]
            }
        ],
        "link": {
            "text": "Check Out the Chess Bots",
            "url": "/project-four"
        },
        "image": "project4.jpg"
    },
    {
        "name": "sentiment1",
        "title": "Sentiment Analysis Series",
        "subtitle": "Data science project using machine learning",
        "sections": [
            {
                "name": "Introduction",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "This project involved building a series of sentiment analysis models using Python and TensorFlow to analyze text data. The goal was to classify text into positive, negative, or neutral sentiments with high accuracy."
                    },
                    {
                        "type": "highlight",
                        "text": "Key achievement: Achieved high accuracy in sentiment classification across diverse datasets."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/sentiment_analysis.png",
                        "alt": "Sentiment analysis visualization"
                    },
                    {
                        "type": "pills",
                        "pills": ["Python", "TensorFlow"]
                    }
                ]
            },
            {
                "name": "Methodology",
                "type": "text",
                "items": [
                    {
                        "type": "paragraph",
                        "text": "The project utilized natural language processing (NLP) techniques, including tokenization, word embeddings, and recurrent neural networks (RNNs). Models were trained on datasets such as IMDb movie reviews and Twitter sentiment data."
                    },
                    {
                        "type": "image",
                        "src": "assets/images/nlp_pipeline.png",
                        "alt": "NLP pipeline diagram"
                    }
                ]
            }
        ],
        "link": {
            "text": "View Sentiment Analysis Results",
            "url": "/project-five"
        },
        "image": "project5.jpg"
    }
]